[{"id": "17fb524b-c716-4a33-9f23-a77ec42fefe9", "title": "Timeseries : Cardinalit\u00e9 et explosion", "date": "2020-01-04 20:12:00", "content": "\n\n\n[Wikip\u00e9dia](https://fr.wikipedia.org/wiki/Cardinalit%C3%A9_(math%C3%A9matiques)) indique :\n\n> En math\u00e9matiques, la cardinalit\u00e9 est une notion de taille pour les ensembles. Lorsqu'un ensemble est fini, c'est-\u00e0-dire si ses \u00e9l\u00e9ments peuvent \u00eatre list\u00e9s par une suite finie, son cardinal est la longueur de cette suite, autrement dit il s'agit du nombre d'\u00e9l\u00e9ments de l'ensemble.\n\nC'est donc le nombre de valeurs uniques d'un ensemble.\n\nDans le cas de Prometheus, la cardinalit\u00e9 d'une m\u00e9trique $M$ est le produit de la cardinalit\u00e9 de ses $n$ labels $L_{n}$ tel que :\n\n$$ Card(M) = \\prod_{n=0}^{X}Card(L_n) $$\n\nAinsi, il est facile d'imaginer une m\u00e9trique `http_request_duration_seconds` ayant les caract\u00e9ristiques suivantes :\n\n* Un label `verb` qui repr\u00e9sente les m\u00e9thodes HTTP et qui a pour valeurs possibles : `GET`, `POST`, `PUT` et `DELETE` ($Card = 4$);\n* Un label `le` qui est le bucket dans lequel la mesure tombe. Il a pour valeurs possibles : 0.1, 0.2, 0.5, 1, `+Inf` ($Card = 5$);\n* Un label `browser` qui indique le navigateur utilis\u00e9 par le client : Chrome, Firefox, IE, Edge, Safari, Opera, Others ($Card = 7$);\n* Un label `device` qui repr\u00e9sente la famille de p\u00e9riph\u00e9rique utilis\u00e9 par le client : Desktop, Mobile, Tablet ($Card = 3$);\n* En enfin, un label `os` qui indique la \"marque\" de l'OS utilis\u00e9 par le client : Linux, Microsoft, Apple ($Card = 3$);\n\nSi la m\u00e9trique n'avait qu'un seul label, voire deux, la cardinalit\u00e9 serait faible. Le probl\u00e8me survient lorsque un label est ajout\u00e9 ou lorsque la cardinalit\u00e9 d'un label augmente subitement. La m\u00e9trique fini inn\u00e9vitablement par arriver \u00e0 une [explosion combinatoire](https://fr.wikipedia.org/wiki/Explosion_combinatoire) : un petit changement du nombre de donn\u00e9es rend la cardinalit\u00e9 de notre m\u00e9trique irraisonable.\n\nAu d\u00e9but, tout commence de mani\u00e8re raisonnable : il n'y a que 2 verbes et 5 buckets. Puis on se dit qu'il faudrait s\u00e9parer par OS. Puis par famille de client. Puis par navigateur. Puis par... Et la cardinalit\u00e9 est pass\u00e9e de $2 \\cdot 5 = 10$ \u00e0 $4 \\cdot 5 \\cdot 7 \\cdot 3 \\cdot 3 = 1260$ !\n\nLe plus surprenant c'est que l'augmentation de la cardinalit\u00e9 des labels augmente consid\u00e9rablement la cardinalit\u00e9 de la m\u00e9trique ! Admettons que chaque cardinalit\u00e9 augmente de 1 (ce qui est peu), la cardinalit\u00e9 de la m\u00e9trique passe de $1260$ \u00e0 $5 \\cdot 6 \\cdot 8 \\cdot 4 \\cdot 4 = 3840$, soit plus du triple de la valeur initiale !\n\nQue va-t'il se passer si l'on d\u00e9cide d'ajouter un label `customer` qui a pour valeur un UUID ? D'apr\u00e8s [Wikip\u00e9dia](https://en.wikipedia.org/wiki/Universally_unique_identifier#Version_4_(random)), un UUID dans sa version 4 a 122 bits g\u00e9n\u00e9r\u00e9s al\u00e9atoirement \u00e0 0 ou 1, soit $2^{122}$ possiblit\u00e9s !\n\n{{< figure src=\"https://media.giphy.com/media/O3GqAYR9jFxLi/source.gif\" title=\"Boooooom\" >}}\n\n \nIl semble \u00e9vident que demander une granularit\u00e9 aussi fine \u00e0 un tel syst\u00e8me est impossible. Les timeseries sont con\u00e7ues pour traiter et afficher des donn\u00e9es en temps r\u00e9el. Malheureusement, le temps r\u00e9el est quelque chose de tr\u00e8s co\u00fbteux, il faut donc faire quelques compromis. Limiter la pr\u00e9cision (et donc la cardinalit\u00e9) est un bon moyen d'\u00e9quilibrer le cout. Il faudrait alors se tourner vers un second syst\u00e8me d\u00e9di\u00e9 \u00e0 de la pr\u00e9cision, tel que l'analyse de logs, pour compl\u00e9ter les mesures.\n\nLes timeseries servent \u00e0 donner une vue d'ensemble d'un syst\u00e8me (que ce soit au niveau d'un serveur, d'une application, d'un cluster, d'un datacenter...) mais ne peuvent pas servir \u00e0 d\u00e9bugger et \u00e0 trouver l'origine d'un probl\u00e8me. Une fois qu'un probl\u00e8me est d\u00e9tect\u00e9, c'est vers les logs qu'il faut se tourner."}, {"id": "d33eab19-b882-49c9-ab25-28872a9070b2", "title": "Graphes : Le danger des s\u00e9ries empil\u00e9es", "date": "2020-05-03 10:33:00", "content": "\n\n\n\nLe graphe suivant montre un nombre de requ\u00eates en fonction du temps sur 4 serveurs. Les s\u00e9ries sont empil\u00e9es afin de pouvoir facilement lire la somme de ces requ\u00eates sur l'ensemble de l'infrastructure.\n\n{{< figure src=\"/images/graphes-le-danger-des-series-empilees/mischievous_node_first.svg\" title=\"Exemple typiques de s\u00e9ries empil\u00e9es : nombre de requ\u00eates en fonction du temps sur 4 serveurs\" >}}\n\nIl est tr\u00e8s facile d'extraire quelques informations : \n\n* 3 des 4 serveurs re\u00e7oivent chacun une dizaine de requ\u00eates par seconde;\n* L'un des serveurs re\u00e7oit plus de requ\u00eates que les autres;\n* L'ensemble de l'infrastructure encaisse une soixantaine de requ\u00eates par seconde;\n\n## Pourquoi les s\u00e9ries empil\u00e9es sont dangereuses ?\n\nIl semble aussi \u00e9vident que l'infrastructure a vu une chute massive des requ\u00eates sur chacun des noeuds.\n\nEn r\u00e9ordonnant les s\u00e9ries en pla\u00e7ant le serveur le plus charg\u00e9 en haut, une diff\u00e9rence int\u00e9r\u00e9ssante se dessine :\n\n{{< figure src=\"/images/graphes-le-danger-des-series-empilees/mischievous_node_last.svg\" title=\"Le m\u00eame exemple avec les s\u00e9ries ordonn\u00e9es diff\u00e9rement\" >}}\n\nToute l'infrastructure n'est pas affect\u00e9e par la diminution brutale du nombre de requ\u00eates mais seulement un des serveurs !\n\n{{< figure src=\"https://media.giphy.com/media/3o7btW7VDxqrhJEnqE/giphy.gif\" title=\"Denis Brogniart est stup\u00e9fait de cette d\u00e9couverte\" width=\"300\" >}}\n\n### Est-ce un probl\u00e8me avec les donn\u00e9es ? Avec le graphe ?\n\nLes s\u00e9ries inf\u00e9rieures influencent la forme des s\u00e9ries sup\u00e9rieures. L'ordre des s\u00e9ries change donc la perception que l'on a d'un graphe et, par cons\u00e9quent, les conclusions qu'on en tire ! \n\nLe fait de pouvoir facilement lire une somme pousse \u00e0 ne plus prendre en compte les diff\u00e9rences entre les s\u00e9ries mais seulement lire la s\u00e9rie la plus haute et ainsi voir, de fa\u00e7on erron\u00e9e, une baisse sur toute l'infrastructure.\n\nCe ne sont ni les donn\u00e9es ni leur repr\u00e9sentation qui sont erron\u00e9es, mais bien la lecture que nous en avons. Sans \u00eatre vigilant, il est facile de penser que la baisse du nombre de requ\u00eates affecte tout l'infrastructure.\n\n## Comment s'en pr\u00e9munir ?\n\nIl est tr\u00e8s facile de se pr\u00e9munir d'une telle erreur d'interpr\u00e9tation : ne pas empiler les s\u00e9ries. Pour pouvoir quand m\u00eame lire un total, il suffit d'ajouter une s\u00e9rie repr\u00e9sentant leur somme :\n\n{{< figure src=\"/images/graphes-le-danger-des-series-empilees/unstacked.svg\" title=\"Le m\u00eame exemple sans empiler les s\u00e9ries et avec une somme des s\u00e9ries (noir)\" >}}\n\nAvec cette repr\u00e9sentation, il apparait de fa\u00e7on tr\u00e8s \u00e9vidente que les variations d'une s\u00e9rie ont bien un effet sur le total (puisqu'il s'agit de la somme des points des s\u00e9ries) mais pas sur les autres s\u00e9ries.\n"}, {"id": "da8d35e9-07a0-4a14-aa7a-9e08fdf451fd", "title": "Esctl: managing elasticsearch from the command line.", "date": "2019-09-22 21:08:00", "content": "\n\nDuring my month of unemployment, I spent time thinking on how I had tackled technical problems in my last year-and-half of work. The best part of my day-to-day mission was to ensure our Elasticsearch clusters were healthy, secured and efficient. To that end, I was using a combination of tools:\n\n* raw `curl` commands,\n* bash scripts I wrote,\n* graphical interfaces,\n* Prometheus monitoring and alerting,\n* Some automation,\n* commands embedded in SaltStack\n\nIt's easy to see there is no common way to manage those clusters, and I was relying on a bunch of disparate stuff.\n\n## The problem\n\nThe issue does not come from Elasticsearch itself but is inherent to any software that exposes an HTTP API to manage itself: curl-of-the-death.\n\nHere are some commands I used to run on a regular basis (examples come from [Elasticsearch's documentation](https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html)).\n\n#### List indices\n\n```bash\n$ curl -X GET \"localhost:9200/_cat/indices\"\nyellow open foo VrIiXmIRRA6BNP5JWaXKqA 1 1 0 0 283b 283b\n```\n\n#### Change the number of replicas of a given index\n\n```bash\n$ curl -X PUT \"localhost:9200/twitter/_settings?pretty\" -H 'Content-Type: application/json' -d'\n{\n    \"index\" : {\n        \"number_of_replicas\" : 2\n    }\n}\n'\n```\n\n#### Reset a index's refresh interval to its default value\n\n```bash\n$ curl -X PUT \"localhost:9200/twitter/_settings?pretty\" -H 'Content-Type: application/json' -d'\n{\n    \"index\" : {\n        \"refresh_interval\" : null\n    }\n}\n'\n```\n\n#### Pretty-print cluster stats\n\n```bash\n$ curl -X GET \"localhost:9200/_cluster/stats\"\n{\n    \"_nodes\": {\n        \"total\": 1,\n        \"successful\": 1,\n        \"failed\": 0\n    },\n    ...\n    \"nodes\": {\n        \"count\": {\n            \"total\": 1,\n            \"data\": 1,\n            \"coordinating_only\": 0,\n            \"master\": 1,\n            \"ingest\": 1\n        },\n        \"versions\": [\n            \"7.2.1\"\n        ],\n        \"jvm\": {\n            \"max_uptime_in_millis\": 1565394,\n            \"versions\": [\n                {\n                    \"version\": \"12.0.1\",\n                    \"vm_name\": \"OpenJDK 64-Bit Server VM\",\n                    \"vm_version\": \"12.0.1+12\",\n                    \"vm_vendor\": \"Oracle Corporation\",\n                    \"bundled_jdk\": true,\n                    \"using_bundled_jdk\": true,\n                    \"count\": 1\n                }\n            ],\n            \"mem\": {\n                \"heap_used_in_bytes\": 128029720,\n                \"heap_max_in_bytes\": 1056309248\n            },\n            \"threads\": 31\n        },\n        ...\n    }\n}\n```\n\n#### Reroute shard 0 of index 'test' from node1 to node2\n\n```bash\n$ curl -X POST \"localhost:9200/_cluster/reroute?pretty\" -H 'Content-Type: application/json' -d'\n{\n    \"commands\" : [\n        {\n            \"move\" : {\n                \"index\" : \"test\", \"shard\" : 0,\n                \"from_node\" : \"node1\", \"to_node\" : \"node2\"\n            }\n        }\n    ]\n}\n'\n```\n\n#### Change cluster's transient setting 'indices.recovery.max_bytes_per_sec' to 20mb\n\n```bash\n$ curl -X PUT \"localhost:9200/_cluster/settings?flat_settings=true&pretty\" -H 'Content-Type: application/json' -d'\n{\n    \"transient\" : {\n        \"indices.recovery.max_bytes_per_sec\" : \"20mb\"\n    }\n}\n'\n```\n\n\nCommands are short, but if I need to pass URL parameters, content type, HTTP verb and a full JSON body, they are no longer short...\n\nOf course, I could use some bash alias to hide the `-H 'Content-Type: application/json'`, or maybe use the excellent [HTTPie](https://httpie.org/) but the biggest pain comes from the JSON body!\n\n\n## Requirements\n\nI needed a tool which could abstract all those long curl commands and could be flexible enough. After looking on the Internet, it appeared the few tools already written didn't support commands I needed. Thus, I decided to write my own, and I came with a list of requirements:\n\n| Requirement | Solution |\n|    |    |\n| Easy and fast to write | Python : high-level, easy to read and write, I know it well |\n| Fast to use | Command-line |\n| Abstract/hide params | Command-line params and integrated help ! I don't want to remember what verb to use, what URL params to give, what to put in the JSON body, etc... |\n| Don't spend time on building CLI | [Openstack's Cliff](https://github.com/openstack/cliff) |\n| Easy to switch cluster, without remembering long server name | Config file |\n| Each cluster may have different setup (ssl, auth, etc...) | Config file |\n| Nice and pretty output | [Cliff](https://github.com/openstack/cliff) comes with [PrettyTable](https://pypi.org/project/PrettyTable/) |\n| Inspiration | [Openstack's CLI](https://github.com/openstack/python-openstackclient) and [kubectl](https://kubernetes.io/docs/reference/kubectl/overview/) |\n\n\n## The solution\n\nI ended up writing [esctl](https://github.com/jeromepin/esctl). It checks all my requirements and it's very easy to add new features by inheriting a class based on the output type.\n\n{{< figure src=\"/images/esctl-CLI-design-tree.svg\" title=\"Esctl subcommands taxonomy\" alt=\"Esctl subcommands taxonomy\" >}}\n\nIt relies on a config file (inspired by `kubectl`) to declare settings (global and cluster-wide), clusters, users and contexts (an association of a user and a cluster) :\n\n```yaml\nsettings:\n  no_check_certificate: true\n  max_retries: 0\n  timeout: 20\n\nclusters:\n  localhost:\n    servers:\n    - http://localhost:9200\n\n  foo01-prd-sfo:\n    servers:\n    - https://master01-foo01-prd-sfo1.example.com\n    - https://master02-foo01-prd-sfo2.example.com\n    - https://master03-foo01-prd-sfo3.example.com\n    settings:\n      timeout: 60\n\nusers:\n  jerome:\n    username: jerome\n    password: P@ssw0rD\n\ncontexts:\n  localhost:\n    cluster: localhost\n\n  production:\n    user: jerome\n    cluster: foo01-prd-sfo\n\ndefault-context: localhost\n```\n\nEsctl provides a lot of commands and subcommands to manage Elasticsearch:\n\n```\nusage: esctl [--version] [-v | -q] [--log-file LOG_FILE] [-h] [--debug] [--context CONTEXT]\n\nesctl\n\noptional arguments:\n  --version            show program's version number and exit\n  -v, --verbose        Increase verbosity of output. Can be repeated.\n  -q, --quiet          Suppress output except warnings and errors.\n  --log-file LOG_FILE  Specify a file to log output. Disabled by default.\n  -h, --help           Show help message and exit.\n  --debug              Show tracebacks on errors.\n  --context CONTEXT    Context to use\n\nCommands:\n  cat allocation                     Show shard allocation.\n  cluster allocation explain         Provide explanations for shard allocations in the cluster.\n  cluster health                     Retrieve the cluster health.\n  cluster routing allocation enable  Change the routing allocation status.\n  cluster stats                      Retrieve the cluster status.\n  complete                           print bash completion command (cliff)\n  config context list                List all contexts.\n  help                               print detailed help for another command (cliff)\n  index close                        Close an index.\n  index create                       Create an index.\n  index delete                       Delete an index.\n  index list                         List all indices.\n  index open                         Open an index.\n  logging get                        Get a logger value.\n  logging reset                      Reset a logger value.\n  logging set                        Set a logger value.\n  node hot-threads                   Print hot threads on each nodes.\n  node list                          List nodes.\n```\n\nIt allows to dramatically shorten previously shown commands :\n\n#### List indices\n\n```bash\n$ esctl index list\n+  -+  --+  --+        +   +   +    +    --+    +      --+\n| Index | Health | Status | UUID                   | Primary | Replica | Docs Count | Docs Deleted | Store Size | Primary Store Size |\n+  -+  --+  --+        +   +   +    +    --+    +      --+\n| foo   | yellow | open   | VrIiXmIRRA6BNP5JWaXKqA | 1       | 1       | 0          | 0            | 283b       | 283b               |\n+  -+  --+  --+        +   +   +    +    --+    +      --+\n```\n\n#### Change the number of replicas of a given index\n\n_Not implemented yet. Would look like :_\n\n```bash\n$ esctl index settings set number_of_replicas 2 --index=twitter\n```\n\n#### Reset a index's refresh interval to its default value\n\n_Not implemented yet. Would look like :_\n\n```bash\n$ esctl index settings reset refresh_interval --index=twitter\n```\n\n#### Pretty-print cluster stats\n\n```bash\n$ esctl cluster stats\n+                +          +\n| Attribute                                      |                        Value |\n+                +          +\n| _nodes.failed                                  |                            0 |\n| _nodes.successful                              |                            1 |\n| _nodes.total                                   |                            1 |\n...\n| nodes.count.coordinating_only                  |                            0 |\n| nodes.count.data                               |                            1 |\n| nodes.count.ingest                             |                            1 |\n| nodes.count.master                             |                            1 |\n| nodes.count.total                              |                            1 |\n| nodes.discovery_types.single-node              |                            1 |\n| nodes.fs.available_in_bytes                    |                  48388599808 |\n| nodes.fs.free_in_bytes                         |                  51605315584 |\n| nodes.fs.total_in_bytes                        |                  62725623808 |\n| nodes.jvm.max_uptime_in_millis                 |                      1565394 |\n| nodes.jvm.mem.heap_max_in_bytes                |                   1056309248 |\n| nodes.jvm.mem.heap_used_in_bytes               |                    128029720 |\n| nodes.jvm.threads                              |                           31 |\n| nodes.jvm.versions[0].bundled_jdk              |                         True |\n| nodes.jvm.versions[0].count                    |                            1 |\n| nodes.jvm.versions[0].using_bundled_jdk        |                         True |\n| nodes.jvm.versions[0].version                  |                       12.0.1 |\n| nodes.jvm.versions[0].vm_name                  |     OpenJDK 64-Bit Server VM |\n| nodes.jvm.versions[0].vm_vendor                |           Oracle Corporation |\n| nodes.jvm.versions[0].vm_version               |                    12.0.1+12 |\n...\n| status                                         |                       yellow |\n| timestamp                                      |                1565893455640 |\n+                +          +\n```\n\n#### Reroute shard 0 of index 'test' from node1 to node2\n\n_Not implemented yet_\n\n#### Change cluster's transient setting 'indices.recovery.max_bytes_per_sec' to 20mb\n\n_Not implemented yet. Would look like :_\n\n```bash\n$ esctl cluster settings set --transient indices.recovery.max_bytes_per_sec 20mb\n```\n\n\n## What a subcommand look likes\n\nI created 3 output class based on Cliff's ones:\n\n* `EsctlCommand` : Doesn't expect any output\n* `EsctlLister` : Expect a list of elements in order to create a multi-columns table\n* `EsctlShowOne` : Expect a key-value list to create a two-columns table\n\nTo add a new subcommand, I only need to choose the output class (and inherit my class from it) and write the `take_action` method:\n\n```python\ndef take_action(self, parsed_args):\n    \"\"\"Generate or retrieve data to be displayed.\n\n    Arguments:\n        parsed_args {argparse.Namespace} -- Arguments from the command line.\n\n    Returns:\n        Any -- The data to be displayed, as specified by Cliff\n    \"\"\"\n\n    return data\n```\n\nHere is, as a sample, the class associated to the `esctl cluster health` command:\n\n```python\nclass ClusterHealth(EsctlShowOne):\n    \"\"\"Retrieve the cluster health.\"\"\"\n\n    def take_action(self, parsed_args):\n        # Retrieve the cluster health using the appropriate elasticsearch-py function. Then order the output and sort it\n        health = self._sort_and_order_dict(Esctl._es.cluster.health())\n\n        # Add coloration of the \"status\" (RED, YELLOW, GREEN) key based on it's value\n        health[\"status\"] = Color.colorize(\n            health.get(\"status\"), getattr(Color, health.get(\"status\").upper())\n        )\n\n        # Return a tuple of tuple. It will lead to a two-column table : \"Attribute\" and \"Value\"\n        return (tuple(health.keys()), tuple(health.values()))\n```\n\nWhich will display :\n\n```\n+           -+     -+\n| Field                            | Value          |\n+           -+     -+\n| active_primary_shards            | 0              |\n| active_shards                    | 0              |\n| active_shards_percent_as_number  | 100.0          |\n| cluster_name                     | docker-cluster |\n| delayed_unassigned_shards        | 0              |\n| initializing_shards              | 0              |\n| number_of_data_nodes             | 1              |\n| number_of_in_flight_fetch        | 0              |\n| number_of_nodes                  | 1              |\n| number_of_pending_tasks          | 0              |\n| relocating_shards                | 0              |\n| status                           | green          |\n| task_max_waiting_in_queue_millis | 0              |\n| timed_out                        | False          |\n| unassigned_shards                | 0              |\n+           -+     -+\n```\n\nInstead of :\n\n```json\n{\n  \"cluster_name\" : \"docker-cluster\",\n  \"status\" : \"green\",\n  \"timed_out\" : false,\n  \"number_of_nodes\" : 1,\n  \"number_of_data_nodes\" : 1,\n  \"active_primary_shards\" : 0,\n  \"active_shards\" : 0,\n  \"relocating_shards\" : 0,\n  \"initializing_shards\" : 0,\n  \"unassigned_shards\" : 0,\n  \"delayed_unassigned_shards\" : 0,\n  \"number_of_pending_tasks\" : 0,\n  \"number_of_in_flight_fetch\" : 0,\n  \"task_max_waiting_in_queue_millis\" : 0,\n  \"active_shards_percent_as_number\" : 100.0\n}\n```"}, {"id": "def5763d-ba55-4eaf-aecf-acf0a1d0d940", "title": "PATCH-er selon la RFC", "date": "2019-04-02 15:08:00", "content": "\n\n\n## PUT: mise \u00e0 jour totale\n\nLa plupart des APIs REST proposent des m\u00e9canismes pour modifier des ressources, notamment gr\u00e2ce au verbe _PUT_ qui permet d'envoyer la ressource \u00e0 mettre \u00e0 jour. _PUT_ pose tout de m\u00eame 3 probl\u00e8mes :\n\n* Il est n\u00e9c\u00e9ssaire de faire un _GET_ au pr\u00e9alable afin d'obtenir la totalit\u00e9 de la ressource\n* Il faut s'assurer que la ressource n'a pas \u00e9t\u00e9 modifi\u00e9e c\u00f4t\u00e9 serveur entre le _GET_ et le _PUT_\n* Il faut envoyer l'int\u00e9gralit\u00e9 de la ressource, y compris les champs qui restent inchang\u00e9s.\n\nLa m\u00e9thode _PUT_ apparait ne pas \u00eatre la solution id\u00e9ale pour effectuer une mise \u00e0 jour partielle.\n\nCertaines API proposent d'exposer directement chaque champ de la ressource et d'utiliser _PUT_ pour faire la mise \u00e0 jour :\n\n```http\nPUT /users/jeromepin/age\n\n24\n```\n\nC'est une solution simple mais qui rajoute beaucoup de complexit\u00e9 dans l'API. Et si le client souhaite mettre \u00e0 jour plusieurs informations, il doit effectuer plusieurs appels _PUT_. La solution n'est toujours pas l\u00e0. Heureusement, la [RFC 5789](https://tools.ietf.org/html/rfc5789) propose un verbe HTTP con\u00e7u pour les mises \u00e0 jour partielles : _PATCH_\n\n## PATCH: mauvais usage\n\n_PATCH_ permet donc de modifier **partiellement** une ressource donn\u00e9e. Ainsi beaucoup d'APIs ont ajout\u00e9 le support de ce verbe au travers d'appels tels que :\n\n```http\nPATCH /users/jeromepin\n\nage=25\n```\n\nou encore :\n\n```http\nPATCH /users/jeromepin\n\n{ \"age\" : \"25\" }\n```\n\n**CE N'EST PAS LE R\u00d4LE DE _PATCH_ !**\n\n_PATCH_ ne doit pas envoyer une partie d'une ressource.\n\n\n## PATCH-er correctement\n\nLe but de _PATCH_ n'est pas seulement de mettre \u00e0 jour une ressource. En r\u00e9alit\u00e9, ce n'est pas du tout la fa\u00e7on dont _PATCH_ doit fonctionner. La RFC indique :\n\n> The difference between the PUT and PATCH requests is reflected in the way the server processes the enclosed entity to modify the resource identified by the Request-URI.  In a PUT request, the enclosed entity is considered to be a modified version of the resource stored on the origin server, and the client is requesting that the stored version be replaced.  With PATCH, however, the enclosed entity contains a set of instructions describing how a resource currently residing on the origin server should be modified to produce a new version.\n\nIl est clairement indiqu\u00e9 que _PATCH_, contrairement \u00e0 _PUT_ qui envoi la nouvelle ressource dans son int\u00e9gralit\u00e9, doit envoyer une **liste d'instructions d\u00e9crivant la fa\u00e7on selon laquelle la ressource situ\u00e9e sur le serveur doit \u00eatre modifi\u00e9e**.\n\nUne requ\u00eate _PATCH_ ressemble \u00e0 \u00e7a :\n\n```http\nPATCH /users/jeromepin HTTP/1.1\nHost: www.example.com\nContent-Type: application/example\n\n[description of changes]\n```\n\n`[description of changes]` est appel\u00e9 \"_patch document_\" (ou plus simplement \"_patch_\"). Le format de ce patch n'est pas d\u00e9fini dans cette RFC est peut-\u00eatre de n'importe quel type comme par exemple la sortie de la commande `diff` :\n\n```http\nPATCH /users/jeromepin HTTP/1.1\nHost: www.example.com\nContent-Type: application/diff\n\n  old-json\t2019-04-01 12:02:50.000000000 +0200\n+++ new-json\t2019-04-01 12:03:00.000000000 +0200\n@@ -1,4 +1,4 @@\n{\n    \"name\": \"Jerome Pin\",\n-   \"age\": 24\n+   \"age\": 25\n}\n```\n\nLe `Content-Type` du _PATCH_ doit \u00eatre adapt\u00e9 au format du patch envoy\u00e9.\n\nLe serveur **DOIT** appliquer la totalit\u00e9 des changements de la requ\u00eate de fa\u00e7on atomique et ne jamais fournir (c.\u00e0.d enregistrer en base ou retourner \u00e0 un client) la ressource partiellement modifi\u00e9e. Si le patch ne peut pas \u00eatre appliqu\u00e9 dans sa totalit\u00e9, alors il ne doit pas \u00eatre appliqu\u00e9 du tout.\n\n\n### Quel format pour un patch ?\n\nLa RFC 5789 est tr\u00e8s souple et n'indique pas de type sp\u00e9cifique pour le format du patch, ainsi, c'est au serveur de veiller \u00e0 supporter le type de patch appropri\u00e9 aux documents qu'il manipule.\n\nHeureusement, pour la manipulation de documents JSON (issus par exemple de base de donn\u00e9es orient\u00e9es documents), les RFC [6901](https://tools.ietf.org/html/rfc6901) et [6902](https://tools.ietf.org/html/rfc6902) d\u00e9finissent respectivement les termes _\"JSON Pointer\"_ et _\"JSON Patch\"_.\n\nUn _\"JSON Pointer\"_ d\u00e9fini une syntaxe sous forme de chaine de caract\u00e8res pour identifier une valeur sp\u00e9cifique au sein d'un objet JSON : `/users/0/email`.\nUn _\"JSON Patch\"_ d\u00e9fini la structure d'un document JSON permettant d'exprimer une s\u00e9rie de modifications \u00e0 appliquer \u00e0 un document JSON :\n\n```json\n[\n     { \"op\": \"test\", \"path\": \"/a/b/c\", \"value\": \"foo\" },\n     { \"op\": \"remove\", \"path\": \"/a/b/c\" },\n     { \"op\": \"add\", \"path\": \"/a/b/c\", \"value\": [ \"foo\", \"bar\" ] },\n     { \"op\": \"replace\", \"path\": \"/a/b/c\", \"value\": 42 },\n     { \"op\": \"move\", \"from\": \"/a/b/c\", \"path\": \"/a/b/d\" },\n     { \"op\": \"copy\", \"from\": \"/a/b/d\", \"path\": \"/a/b/e\" }\n]\n```\n\nAvec ces deux nouvelles RFC, il est possible d'effectuer une requ\u00eate _PATCH_ pour enfin modifier un document JSON :\n\n```http\nPATCH /users/jeromepin HTTP/1.1\nHost: www.example.com\nContent-Type: application/json-patch+json\n\n[\n    { \"op\": \"replace\", \"path\": \"/age\", \"value\": \"25\" }\n]\n```\n\nDans le cas o\u00f9 le serveur manipule du XML, une [RFC](http://tools.ietf.org/html/rfc5261) d\u00e9crit un format \u00e9quivalent au JSON-Patch.\n\n## Conclusion\n\nCet usage de _PATCH_ reste tr\u00e8s peu connu. Il est cens\u00e9 \u00eatre le standard \u00e0 utiliser pour des mises \u00e0 jour partielles, mais il est facile de s'aper\u00e7evoir qu'un tel fonctionnement complexifie la gestion du serveur et la fa\u00e7on dont nous avons l'habitude d'utiliser les verbes plus traditionnels (_GET_, _POST_, _PUT_). La RFC \u00e9tant tr\u00e8s souple, il est tout \u00e0 fait possible d'utiliser son propre format de patch, ainsi pour incr\u00e9menter l'age, il est possible de faire quelque chose comme :\n\n```http\nPATCH /users/jeromepin HTTP/1.1\nHost: www.example.com\nContent-Type: application/custom-format+json\n\n[\n    { \"increment\": \"age\" }\n]\n```\n\n\u00c9videmment, d'un point de vue conceptuel, il faut alors se demander si cette fa\u00e7on d'envoyer des actions plut\u00f4t que des \u00e9tats est compatible avec la philosophie REST ? N'est-ce pas plus proche de RPC ?\n"}, {"id": "05f375d2-9a94-4ea0-9569-c07649931ec0", "title": "Construire de bons microservices", "date": "2018-09-02 13:51:00", "content": "\n\n\n## Configuration\n\nLa configuration d'un service doit \u00eatre optionnelle et tous ses param\u00e8tres doivent avoir une valeur par d\u00e9faut :\n\n```javascript\nconst ELASTICSEARCH_HOST = process.env.ELASTICSEARCH_HOST || 'localhost';\n```\n\nOu encore :\n\n```bash\nELASTICSEARCH_HOST=${$ELASTICSEARCH_HOST:-localhost} \n```\n\nChaque \u00e9l\u00e9ment de configuration doit \u00eatre modifiable par une variable d'environnement correctement nomm\u00e9e. L'int\u00e9r\u00eat est de permettre de changer le comportement de l'application au _runtime_ plut\u00f4t qu'au _buildtime_. De plus, l'usage d'orchestrateurs de conteneurs comme _Docker Swarm_ ou _Kubernetes_ rendent plus pratique le passage de variables d'environnement que de fichiers de configuration.\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: foo\nspec:\n  containers:\n  - name: foo\n    image: foo:1.0\n    env:\n    - name: ELASTICSEARCH_HOST\n      value: \"elasticsearch.example.com\"\n```\n\n\n\n## Signaux et fermeture\n\nUne application doit \u00eatre en mesure de r\u00e9agir aux [signaux](http://man7.org/linux/man-pages/man7/signal.7.html) envoy\u00e9s par l'OS et en tirer parti. Par exemple, [Prometheus](https://prometheus.io) recharge sa configuration \u00e0 la r\u00e9ception d'un SIGHUP :\n\n```bash\n$ kill -HUP 1234\nINFO[1234] Loading configuration file prometheus.yml source=main.go:201\nINFO[1234] Stopping target manager... source=targetmanager.go:281\nINFO[1234] Target manager stopped. source=targetmanager.go:216\nINFO[1234] Starting target manager... source=targetmanager.go:122\n```\n\nL'application doit s'\u00e9teindre proprement lorsqu'elle re\u00e7oit un `SIGTERM`. Elle doit pouvoir nettoyer tous les \u00e9l\u00e9ments externes dont elle a eu besoin : connections ouvertes, caches utilis\u00e9s, fichiers ouverts, fichiers temporaires cr\u00e9\u00e9s, etc...\n\n## Logs\n\nLa gestion des logs est souvent bien plus complexe que ce que l'on pense. Il est donc g\u00e9n\u00e9ralement int\u00e9ressant de faire usage d'une librairie d\u00e9di\u00e9e. Cette librairie est en charge de diff\u00e9rents param\u00e8tres :\n\n* format : JSON, cl\u00e9-valeur\n* contexte : date et heure, module \u00e9m\u00e9tteur\n* export : r\u00e9seau (`tcp/udp`, `http`, `kafka`, ...), `syslog`, fichiers\n* rotation\n\nDans le cas d'un microservice, l'application ne doit pas s'occuper du routage et du stockage de ses logs. Elle doit simplement \u00e9crire dans `stdout` et `stderr` en fonction des besoins, et laisser un routeur de logs (comme [fluentd](https://github.com/fluent/fluentd) ou [filebeat](https://www.elastic.co/products/beats/filebeat)) g\u00e9rer et acheminer les logs.\n\nChaque message de log doit \u00eatre associ\u00e9 au bon niveau (`debug`, `info`, `warn`, `error`, ...) pour qu'il puisse \u00eatre affich\u00e9 et/ou trait\u00e9 de fa\u00e7on optimale. Il peut \u00eatre int\u00e9ressant d'afficher un message pour certains cas :\n\n* Message de d\u00e9marrage de l'application;\n* Ports sur lesquels elle \u00e9coute;\n* Services auxquels elle est connect\u00e9e;\n* \u00c9v\u00e8nements pr\u00e9vus et impr\u00e9vus;\n* Signaux re\u00e7us;\n* Fermeture;\n\n> [foo] [INFO] Listening on port 80\n\n> [foo] [INFO] Connected to mysql://foo:bar@host:port/database. Alive and kicking !\n\n> ...\n\n> [foo] [INFO] SIGHUP received. Reloading configuration\n\n> ...\n \n> [foo] [INFO] Shutting down... Closing connexions, removing temporary files\n\n\n## Choix du langage\n\n### \u00c9viter les langages \u00e0 machines virtuelles\n\nLes langages bas\u00e9s sur des machines virtuelles (Java, Clojure, Erlang, .NET) sont plus lents \u00e0 d\u00e9marrer et ont n\u00e9cessairement besoin de plus de ressources. De plus, ces machines virtuelles sont g\u00e9n\u00e9ralement con\u00e7ues pour g\u00e9rer de large applications monolithiques qui ont besoin de fonctionnalit\u00e9s avanc\u00e9es de gestion de m\u00e9moire, de CPU, de threads, etc... Ces fonctionnalit\u00e9s sont redondantes avec les orchestrateurs et les runtimes et peuvent cr\u00e9er des conflits, comme par exemple la JVM qui ne supporte pas (ou mal) les limites de CPU et de m\u00e9moire d\u00e9finies dans un conteneur. Seules les [versions les plus r\u00e9centes du JDK 10](https://bugs.openjdk.java.net/browse/JDK-8196595) permettent une prise en charge correcte de ces param\u00e8tres.\n\n### Cr\u00e9er des binaires statiques\n\nUtiliser un langage qui cr\u00e9e des binaires statiques pr\u00e9sente plusieurs avantages :\n\n* le binaire est portable : les librairies li\u00e9es sont distribu\u00e9es avec le binaire;\n* il n'est pas n\u00e9cessaire d'avoir une arborescence compl\u00e8te d'un OS (`/bin`, `/usr/bin`, `/tmp`, etc...) pour ex\u00e9cuter le binaire;\n* la construction du binaire est pr\u00e9visible;\n* le binaire est moins sensible aux contaminations de ses librairies par des tierces-parties;\n\nC'est avec toutes ces contraintes que des langages comme [Go](https://golang.org/) et [Rust](https://www.rust-lang.org/) ont vu leur popularit\u00e9 cro\u00eetre \u00e9norm\u00e9ment ces derni\u00e8re ann\u00e9es.\n\nPour un m\u00eame programme C++ :\n\n```cpp\n#include <iostream>\n\nint main() {\n    std::cout << \"Foo\";\n    return 0;\n}\n```\n\nLe binaire compil\u00e9 dynamiquement p\u00e8se 7.8Ko contre 1.6Mo statiquement. La diff\u00e9rence vient de la pr\u00e9sence (ou non) des librairies n\u00e9cessaires au sein du binaire.\n\nLa commande `ldd` permet de conna\u00eetre les librairies li\u00e9es au binaire :\n\n```bash\n$ g++ -o foo foo.cpp\n$ ldd foo\n\tlinux-vdso.so.1 (0x00007fffc9ff8000)\n\tlibstdc++.so.6 => /usr/lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007f6c9c4b6000)\n\tlibm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007f6c9c1b5000)\n\tlibgcc_s.so.1 => /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007f6c9bf9f000)\n\tlibc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f6c9bbf4000)\n\t/lib64/ld-linux-x86-64.so.2 (0x00007f6c9c7c1000)\n```\n\nMon binaire `foo` requiert notamment `libstdc++.so.6 ` (`/usr/lib/x86_64-linux-gnu/libstdc++.so.6`) et `libc.so.6` (`/lib/x86_64-linux-gnu/libc.so.6`). Si je distribue ce binaire sur une autre machine, il faudra non seulement qu'elle tourne sur le m\u00eame OS, mais aussi que les librairies soient les m\u00eames (chemin et version) :\n\n```bash\n$ mv /lib/x86_64-linux-gnu/libc.so.6 /lib/x86_64-linux-gnu/libc.so.6.old\n$ ./foo\n./foo: error while loading shared libraries: libc.so.6: cannot open shared object file: No such file or directory\n```\n\n\n## Stateless vs Stateful\n\nUn bon conteneur est un conteneur que l'on peut d\u00e9placer et red\u00e9marrer \u00e0 la demande, sans pr\u00e9-requis. Il faut donc qu'il soit le plus possible `stateless` : toutes les donn\u00e9es persistantes dont a besoin l'application doivent \u00eatre stock\u00e9es dans des syst\u00e8mes externes comme une base de donn\u00e9es. Il ne doit pas y avoir de diff\u00e9rence entre plusieurs instances d'une application.\n\n\n## Robustesse, healthchecks et timeouts\n\nL'application doit \u00eatre en mesure de g\u00e9rer les erreurs via une d\u00e9gradation de service ou via du _back-off_ plut\u00f4t que de crasher. Elle doit pouvoir non-seulement r\u00e9pondre \u00e0 des _health checks_ (via une route http par exemple) mais aussi en \u00e9mettre afin de surveiller la disponibilit\u00e9 des services li\u00e9s.\n\n\u00c0 un stade plus avanc\u00e9, l'application doit supporter des m\u00e9canismes plus complexes comme les _timeouts_, le _throttling_ et les [circuit-breakers](https://en.wikipedia.org/wiki/Circuit_breaker_design_pattern).\n"}, {"id": "5c974f7c-ba86-4a78-a66c-35664a7212c4", "title": "Sharding : Propri\u00e9t\u00e9s et fonctionnement", "date": "2018-07-12 07:54:00", "content": "\n\nLe sharding (aussi souvent nomm\u00e9 _horizontal partitioning_) est une m\u00e9thode de s\u00e9paration des donn\u00e9es d'une base de donn\u00e9es en plusieurs groupes logiques, g\u00e9n\u00e9ralement r\u00e9partis sur plusieurs n\u0153uds d'un cluster.\n\nLe sharding a plusieurs avantages :\n\n* d\u00e9passer les limitations d'une machine seule (CPU, stockage, etc...);\n* effectuer des traitements concurrents;\n* limiter la diffusion d'une requ\u00eate \u00e0 un sous-set de donn\u00e9es;\n\nLe sharding est souvent impl\u00e9ment\u00e9 au niveau de la base de donn\u00e9e elle-m\u00eame (comme [Elasticsearch](https://www.elastic.co/guide/en/elasticsearch/reference/6.2/_basic_concepts.html#getting-started-shards-and-replicas), Cassandra ou [MongoDB](https://docs.mongodb.com/manual/sharding/)) mais peut aussi l'\u00eatre au niveau applicatif pour supporter des bases de donn\u00e9es o\u00f9 le sharding n'est pas natif (comme [Redis](https://redis.io/topics/partitioning)).\n\nIl existe plusieurs strat\u00e9gies pour distribuer des donn\u00e9es dans plusieurs base de donn\u00e9es. Chacune a ses avantages et ses inconv\u00e9nients et doit \u00eatre choisie avec soin en fonction des besoins et des contraintes. Quelle que soit la strat\u00e9gie choisie, il faut toujours prendre en compte les possibles **hotspots** : une distribution in\u00e9gale des donn\u00e9es entraine une surutilisation de certains shards et r\u00e9duit presque \u00e0 n\u00e9ant l'int\u00e9r\u00eat du sharding.\n\n## Principes de base\n\n### Notions\n\n* cl\u00e9 de shard : (_shard key_) Suite de caract\u00e8res qui identifie de fa\u00e7on unique un shard.\n* shard logique : (_logical shard_) Ensemble de donn\u00e9es stock\u00e9es sur un seul n\u0153ud et partageant la m\u00eame cl\u00e9 de shard.\n* shard physique : (_physical shard_) Un n\u0153ud du cluster, il peut contenir plusieurs shards logiques.\n\n### Comment les donn\u00e9es sont lues et \u00e9crites\n\nLes bases de donn\u00e9es sont utilis\u00e9es pour stocker des donn\u00e9es. Par cons\u00e9quent le choix de la strat\u00e9gie de sharding d\u00e9pend de ces acc\u00e8s. Il s'agit de d\u00e9finir \u00e0 l'avance les [SLOs](https://landing.google.com/sre/sre-book/chapters/service-level-objectives/) :\n\n* Quelle est la distribution entre la lecture et l'\u00e9criture ? (50/50, 80/20, etc...)\n* Quels volumes sont g\u00e9r\u00e9s ?\n* Quels sont les objectifs de performance ? (latence, vitesse, etc...)\n\n### Comment les donn\u00e9es sont distribu\u00e9es\n\nLes **hotspot** contrebalancent presque totalement l'int\u00e9r\u00eat du sharding. Il faut donc choisir avec soin le crit\u00e8re sur lequel les donn\u00e9es vont \u00eatre distribu\u00e9es. Se baser sur une cl\u00e9 trop commune et non-uniform\u00e9ment distribu\u00e9e va cr\u00e9er un d\u00e9s\u00e9quilibre dans la r\u00e9partition de nos donn\u00e9es.\n\nPar exemple, dans une base de donn\u00e9es qui stocke des documents utilisateurs, distribuer les donn\u00e9es en se basant sur l'identifiant de l'utilisateur est une mauvaise id\u00e9e. Si un utilisateur enregistre beaucoup plus de documents que les autres, le shard auquel il est associ\u00e9 va cro\u00eetre fortement. Que va-t-il se passer lorsque ce shard d\u00e9passera la taille d'un n\u0153ud ? Comment ce shard va impacter les performances du reste du cluster ?\n\n### Comment g\u00e9rer la redistribution des donn\u00e9es\n\nUne fois que les questions ci-dessus sont trait\u00e9es, que le cluster fonctionne et que l'utilisation prend de l'ampleur, un premier probl\u00e8me survient : comment ajouter/modifier/supprimer des n\u0153uds sans affecter les performances ?\n\nLors de la modification de l'\u00e9tat du cluster, les donn\u00e9es stock\u00e9es vont devoir \u00eatre redistribu\u00e9es et il va falloir en d\u00e9placer de grandes quantit\u00e9s rapidement sans avoir d'incidence sur les performances.\n\n\n\n## Sharding algorithmique\n\nLe sharding algorithmique (aussi nomm\u00e9 _Client side partitioning_) permet au client de d\u00e9terminer le shard sans aide ext\u00e9rieure, en se basant uniquement sur une fonction g\u00e9n\u00e9ralement de la forme `hash(key) % num_nodes`.\n\n[Elasticsearch](https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-routing-field.html) utilise cette strat\u00e9gie pour d\u00e9finir sur quel shard doit se trouver un document :\n```\nshard_num = hash_murmur3(doc._id) % num_primary_shards\n```\n\nLe sharding algorithmique distribue les donn\u00e9es en se basant uniquement sur cette fonction, et ne prend en compte aucun param\u00e8tre ext\u00e9rieur comme le taux d'utilisation d'un n\u0153ud, la taille de la donn\u00e9e \u00e0 traiter, etc...\n\nRedistribuer les donn\u00e9es peut s'av\u00e9rer complexe : cela requiert non seulement de d\u00e9placer les donn\u00e9es mais aussi de mettre \u00e0 jour la fonction utilis\u00e9e. La fonction id\u00e9ale ne devrait pas n\u00e9cessiter de d\u00e9placer plus de `1/n` donn\u00e9es et ne devrait pas d\u00e9placer des donn\u00e9es qui n'ont pas besoin de l'\u00eatre.\n\n\n## Sharding dynamique\n\nLe sharding dynamique (parfois nomm\u00e9 _Proxy assisted partitioning_) n\u00e9cessite un **service externe** pour d\u00e9terminer l'emplacement d'une donn\u00e9e. Ce service agit comme un annuaire et indique la correspondance entre une cl\u00e9 (ou un ensemble de cl\u00e9s) et le shard sur lequel cette cl\u00e9 est assign\u00e9e. Par exemple, [HDFS](https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html#NameNode_and_DataNodes) utilise un _Namenode_ pour stocker ses m\u00e9tadonnn\u00e9es.\n\n| range\t\t| shard \t\t|\n|    |    -|\n| 0, 3\t\t\t| 0\t\t\t\t|\n| 4, 7\t\t\t| 1\t\t\t\t|\n| 8, B\t\t\t| 2\t\t\t\t|\n| C, F\t\t\t| 3\t\t\t\t|\n\nPour lire ou \u00e9crire une donn\u00e9e, les clients ont n\u00e9cessairement besoin de contacte le service de localisation. Celui va ensuite contacter la base de donn\u00e9es elle-m\u00eame, faisant office de proxy.\n\nCe service externe permet de mieux g\u00e9rer les donn\u00e9es non-uniform\u00e9ment distribu\u00e9es puisque les ensembles de cl\u00e9s n'ont pas besoin d'\u00eatre de taille identique mais peuvent varier en fonction des besoins.\n\nEn revanche, il devient aussi un point de d\u00e9faillance unique : chaque lecture ou \u00e9criture a besoin d'y acc\u00e9der, il faut donc que la stabilit\u00e9 et les performances soient au rendez-vous. Il ne peut pas \u00eatre cach\u00e9 ni dupliqu\u00e9  facilement : des donn\u00e9es obsol\u00e8tes causeraient un d\u00e9sastre sur le cluster.\n\n\n## Conclusion\n\nLe sharding ajoute de la complexit\u00e9 non seulement en termes de d\u00e9veloppement mais aussi d'op\u00e9rations : les donn\u00e9es ne sont plus stock\u00e9es au m\u00eame endroit, le r\u00e9seau introduit de la latence, la topologie change, plus de serveurs doivent \u00eatre configur\u00e9s, etc...\n\nLe sharding ne doit pas \u00eatre le premier axe d'am\u00e9lioration. Bien conna\u00eetre les donn\u00e9es que \u00e0 stocker et la fa\u00e7on dont elles vont \u00eatre utilis\u00e9es est beaucoup plus important. Utiliser un serveur plus puissant suffit souvent \u00e0 r\u00e9gler les probl\u00e8mes de performances tant que l'\u00e9chelle reste mod\u00e9r\u00e9e.\n\nSi l'application est limit\u00e9e par les performances de lecture de la base de donn\u00e9es, ajouter des **caches** ou des **replicas de lecture** peut corriger le probl\u00e8me sans ajouter trop de complexit\u00e9.\n\nEnfin, il est important de s'assurer que les donn\u00e9es sont organis\u00e9es de fa\u00e7on optimale : les blobs sont sur un stockage externe (syst\u00e8me de fichier, stockage objets, etc...), l'analyse et la recherche sont d\u00e9l\u00e9gu\u00e9s \u00e0 d'autres syst\u00e8mes, etc...\n\n"}]